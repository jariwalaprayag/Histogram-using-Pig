#!/bin/bash
#SBATCH -A uot143
#SBATCH --job-name="histogram"
#SBATCH --output="histogram.distr.out"
#SBATCH --partition=compute
## allocate 2 nodes for the Hadoop cluster: 2 datanodes, from which 1 is namenode
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=2
#SBATCH --mem=5G
#SBATCH --export=ALL 
#SBATCH --time=60

export PIG_HOME=/oasis/projects/nsf/uot143/fegaras/pig-0.16.0
export HADOOP_CONF_DIR=/home/$USER/cometcluster
export PIG_CLASSPATH=$HADOOP_CONF_DIR
export HADOOP_MAPRED_LOG_DIR=/tmp

module load hadoop/2.6.0
export JAVA_HOME=/lib/jvm/java
myhadoop-configure.sh
start-dfs.sh
start-yarn.sh
mr-jobhistory-daemon.sh start historyserver

hdfs dfs -mkdir -p /user/$USER
hdfs dfs -put pixels-large.txt /user/$USER/pixels-large.txt
$PIG_HOME/bin/pig -x mapreduce -param P=/user/$USER/pixels-large.txt -param O=/user/$USER/output histogram.pig
rm -rf output-distr
mkdir output-distr
hdfs dfs -get /user/$USER/output/part* output-distr

mr-jobhistory-daemon.sh stop historyserver
stop-yarn.sh
stop-dfs.sh
myhadoop-cleanup.sh
